{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import calendar\n",
    "import time\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading flow with rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"rainfalls\": [\n",
      "        \"rainfall\"\n",
      "    ], \n",
      "    \"name\": \"thorium-large\", \n",
      "    \"start-date\": \"2015-06-02\", \n",
      "    \"flows\": [\n",
      "        \"flow1\", \n",
      "        \"flow2\", \n",
      "        \"flow3\", \n",
      "        \"flow4\", \n",
      "        \"flow5\"\n",
      "    ], \n",
      "    \"split-date\": \"2017-01-01\", \n",
      "    \"end-date\": \"2017-10-01\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow1</th>\n",
       "      <th>flow1_edited</th>\n",
       "      <th>flow2</th>\n",
       "      <th>flow2_edited</th>\n",
       "      <th>flow3</th>\n",
       "      <th>flow3_edited</th>\n",
       "      <th>flow4</th>\n",
       "      <th>flow4_edited</th>\n",
       "      <th>flow5</th>\n",
       "      <th>flow5_edited</th>\n",
       "      <th>rainfall1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>93.889999</td>\n",
       "      <td>93.889999</td>\n",
       "      <td>420.320007</td>\n",
       "      <td>420.320007</td>\n",
       "      <td>252.089996</td>\n",
       "      <td>252.089996</td>\n",
       "      <td>225.460007</td>\n",
       "      <td>225.460007</td>\n",
       "      <td>146.110001</td>\n",
       "      <td>146.110001</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:05:00</th>\n",
       "      <td>93.480003</td>\n",
       "      <td>93.480003</td>\n",
       "      <td>416.660004</td>\n",
       "      <td>416.660004</td>\n",
       "      <td>251.850006</td>\n",
       "      <td>251.850006</td>\n",
       "      <td>225.470001</td>\n",
       "      <td>225.470001</td>\n",
       "      <td>145.320007</td>\n",
       "      <td>145.320007</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:10:00</th>\n",
       "      <td>92.830002</td>\n",
       "      <td>92.830002</td>\n",
       "      <td>416.670013</td>\n",
       "      <td>416.670013</td>\n",
       "      <td>260.440002</td>\n",
       "      <td>260.440002</td>\n",
       "      <td>225.190002</td>\n",
       "      <td>225.190002</td>\n",
       "      <td>144.899994</td>\n",
       "      <td>144.899994</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:15:00</th>\n",
       "      <td>92.199997</td>\n",
       "      <td>92.199997</td>\n",
       "      <td>415.059998</td>\n",
       "      <td>415.059998</td>\n",
       "      <td>255.789993</td>\n",
       "      <td>255.789993</td>\n",
       "      <td>225.229996</td>\n",
       "      <td>225.229996</td>\n",
       "      <td>140.699997</td>\n",
       "      <td>140.699997</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:20:00</th>\n",
       "      <td>91.959999</td>\n",
       "      <td>91.959999</td>\n",
       "      <td>414.279999</td>\n",
       "      <td>414.279999</td>\n",
       "      <td>255.550003</td>\n",
       "      <td>255.550003</td>\n",
       "      <td>225.699997</td>\n",
       "      <td>225.699997</td>\n",
       "      <td>140.259995</td>\n",
       "      <td>140.259995</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         flow1  flow1_edited       flow2  flow2_edited  \\\n",
       "time                                                                     \n",
       "2016-01-01 00:00:00  93.889999     93.889999  420.320007    420.320007   \n",
       "2016-01-01 00:05:00  93.480003     93.480003  416.660004    416.660004   \n",
       "2016-01-01 00:10:00  92.830002     92.830002  416.670013    416.670013   \n",
       "2016-01-01 00:15:00  92.199997     92.199997  415.059998    415.059998   \n",
       "2016-01-01 00:20:00  91.959999     91.959999  414.279999    414.279999   \n",
       "\n",
       "                          flow3  flow3_edited       flow4  flow4_edited  \\\n",
       "time                                                                      \n",
       "2016-01-01 00:00:00  252.089996    252.089996  225.460007    225.460007   \n",
       "2016-01-01 00:05:00  251.850006    251.850006  225.470001    225.470001   \n",
       "2016-01-01 00:10:00  260.440002    260.440002  225.190002    225.190002   \n",
       "2016-01-01 00:15:00  255.789993    255.789993  225.229996    225.229996   \n",
       "2016-01-01 00:20:00  255.550003    255.550003  225.699997    225.699997   \n",
       "\n",
       "                          flow5  flow5_edited  rainfall1  \n",
       "time                                                      \n",
       "2016-01-01 00:00:00  146.110001    146.110001      0.254  \n",
       "2016-01-01 00:05:00  145.320007    145.320007      0.254  \n",
       "2016-01-01 00:10:00  144.899994    144.899994      0.254  \n",
       "2016-01-01 00:15:00  140.699997    140.699997      0.254  \n",
       "2016-01-01 00:20:00  140.259995    140.259995      0.254  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_FOLDER = './data/'\n",
    "\n",
    "with open(PROJECT_FOLDER + 'project.json', 'r') as file:\n",
    "    project = json.load(file)\n",
    "print(json.dumps(project, indent=4))\n",
    "\n",
    "def load_series(fname, name):\n",
    "    path = PROJECT_FOLDER + fname + '.csv'\n",
    "    xs = pd.read_csv(path, parse_dates=['time'])\n",
    "    xs = xs.set_index('time')[name].fillna(0)\n",
    "    xs = xs.resample('5T').pad()\n",
    "    xs = xs.rename(fname)\n",
    "    return xs\n",
    "    \n",
    "\n",
    "flow1_raw = load_series('flow1', 'flow')\n",
    "flow1_edited = load_series('flow1_edited', 'flow_edited')\n",
    "\n",
    "flow2_raw = load_series('flow2', 'flow')\n",
    "flow2_edited = load_series('flow2_edited', 'flow_edited')\n",
    "\n",
    "flow3_raw = load_series('flow3', 'flow')\n",
    "flow3_edited = load_series('flow3_edited', 'flow_edited')\n",
    "\n",
    "flow4_raw = load_series('flow4', 'flow')\n",
    "flow4_edited = load_series('flow4_edited', 'flow_edited')\n",
    "\n",
    "flow5_raw = load_series('flow5', 'flow')\n",
    "flow5_edited = load_series('flow5_edited', 'flow_edited')\n",
    "\n",
    "rainfall = load_series('rainfall1', 'rainfall')\n",
    "df = pd.concat(\n",
    "    [flow1_raw, \n",
    "     flow1_edited,\n",
    "     flow2_raw, \n",
    "     flow2_edited,\n",
    "     flow3_raw, \n",
    "     flow3_edited,\n",
    "     flow4_raw, \n",
    "     flow4_edited,\n",
    "     flow5_raw, \n",
    "     flow5_edited,\n",
    "     rainfall\n",
    "    ], axis=1)\n",
    "data_frame = df['2016-01-01':]\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/air_passengers.csv', parse_dates=['date'])\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(data.date, data.y, '.-', c='gray')\n",
    "\n",
    "t_diff_median = data.date.diff().median()\n",
    "print 'Average time step: {!s}'.format(t_diff_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(t, X, y, distance, test_size=0.2, log_transform=False, estimator=None, plot=False):\n",
    "    \n",
    "    # apply forecast distance\n",
    "    X = X.shift(distance)\n",
    "    \n",
    "    # ignore missing value rows\n",
    "    non_null = X.dropna(how='any').index.values\n",
    "\n",
    "    # create holdout set\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = int(test_size * len(t))\n",
    "    train = non_null[:-test_size]\n",
    "    test  = non_null[-test_size:]\n",
    "\n",
    "    # standardize\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    centers = X.loc[train, numeric_cols].mean(axis=0)\n",
    "    scales = np.maximum(1e-15, X.loc[train, numeric_cols].std(axis=0))\n",
    "    X[numeric_cols] = (X[numeric_cols] - centers)/scales\n",
    "    \n",
    "    # fit model\n",
    "    if estimator is None:\n",
    "        estimator = ElasticNetCV(n_alphas=100, l1_ratio=0.9, cv=5, random_state=123)\n",
    "    if log_transform:\n",
    "        estimator = MultiplicativeEstimator(estimator)\n",
    "    estimator.fit(X.loc[train, :], y[train])\n",
    "    test_score = estimator.score(X.loc[test, :], y[test])\n",
    "\n",
    "    # plot the fit\n",
    "    if plot:\n",
    "        plt.figure(figsize=(9,3))\n",
    "        plt.plot(t, y, '.', c='gray', alpha=0.7)\n",
    "        plt.plot(t[train], estimator.predict(X.loc[train, :]), 'b-', lw=2, alpha=0.7)\n",
    "        plt.plot(t[test], estimator.predict(X.loc[test, :]),  'r-', lw=2, alpha=0.7)\n",
    "        plt.annotate('Test Score: {}'.format(test_score), \n",
    "                     xy=(0, 1), xytext=(12, -12), va='top', \n",
    "                     xycoords='axes fraction', textcoords='offset points')\n",
    "        plt.show()\n",
    "    return estimator, test_score\n",
    "\n",
    "\n",
    "def feature_importance_summary(model):\n",
    "    if hasattr(model, 'coef_'):\n",
    "        coef = pd.Series(model.coef_, index=X.columns, name='Importance')\n",
    "        importances = coef.abs()\n",
    "        importances.sort_values(ascending=False, inplace=True)\n",
    "        importances = importances[importances > 1e-15]\n",
    "        display(importances.to_frame().style.bar())\n",
    "    else:\n",
    "        raise NotImplemented('Only linear models supported at the momemnt.')\n",
    "        \n",
    "\n",
    "class MultiplicativeEstimator(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        self.estimator.fit(X, np.log(y), *args, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.exp(self.estimator.predict(X))\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.estimator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv('data/air_passengers.csv', parse_dates=['date'])\n",
    "t = data['date']\n",
    "y = data['y']\n",
    "\n",
    "# create features in new dataframe\n",
    "X = pd.DataFrame()\n",
    "X['lag 0'] = y.shift(0)\n",
    "X['lag 1'] = y.shift(1)\n",
    "X['lag 2'] = y.shift(2)\n",
    "X['lag 3'] = y.shift(3)\n",
    "X['lag 4'] = y.shift(4)\n",
    "X['lag 5'] = y.shift(5)\n",
    "X['lag 6'] = y.shift(6)\n",
    "X['lag 7'] = y.shift(7)\n",
    "X['lag 8'] = y.shift(8)\n",
    "X['lag 9'] = y.shift(9)\n",
    "X['lag 10'] = y.shift(10)\n",
    "X['lag 11'] = y.shift(11)\n",
    "X['lag 12'] = y.shift(12)\n",
    "\n",
    "# fit\n",
    "model, score = fit_model(t, X, y, plot=True, distance=12)\n",
    "\n",
    "# display importances\n",
    "feature_importance_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv('data/air_passengers.csv', parse_dates=['date'])\n",
    "t = data['date']\n",
    "y = data['y']\n",
    "X = pd.DataFrame()\n",
    "\n",
    "lag_counts = range(0, 20)\n",
    "scores = []\n",
    "\n",
    "for i in lag_counts:\n",
    "    X['lag {}'.format(i)] = y.shift(i)\n",
    "    model, score = fit_model(t, X, y, distance=12)\n",
    "    scores.append(score)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(lag_counts, scores, lw=2)\n",
    "plt.xlabel('# of Lags')\n",
    "plt.ylabel('Test Score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Types of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv('data/air_passengers.csv', parse_dates=['date'])\n",
    "t = data['date']\n",
    "y = data['y']\n",
    "\n",
    "# create features in new dataframe\n",
    "X = pd.DataFrame()\n",
    "X['lag 0'] = y.shift(0)\n",
    "X['lag 1'] = y.shift(1)\n",
    "X['lag 2'] = y.shift(2)\n",
    "X['lag 3'] = y.shift(3)\n",
    "X['lag 4'] = y.shift(4)\n",
    "X['lag 5'] = y.shift(5)\n",
    "X['lag 6'] = y.shift(6)\n",
    "X['lag 7'] = y.shift(7)\n",
    "X['lag 8'] = y.shift(8)\n",
    "X['lag 9'] = y.shift(9)\n",
    "X['lag 10'] = y.shift(10)\n",
    "X['lag 11'] = y.shift(11)\n",
    "X['lag 12'] = y.shift(12)\n",
    "X['t'] = (t - t.min())/(t.max() - t.min())\n",
    "X['rolling mean 3'] = y.rolling(3).mean()\n",
    "X['rolling mean 6'] = y.rolling(6).mean()\n",
    "X['rolling mean 12'] = y.rolling(12).mean()\n",
    "X['rolling std 12'] = y.rolling(12).std()\n",
    "X['rolling min 12'] = y.rolling(12).min()\n",
    "X['rolling max 12'] = y.rolling(12).max()\n",
    "X['rolling median 12'] = y.rolling(12).median()\n",
    "\n",
    "model, score = fit_model(t, X, y, plot=True, distance=12)\n",
    "\n",
    "feature_importance_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_counts = range(X.shape[0] / 2, X.shape[0] + 1)\n",
    "scores = []\n",
    "\n",
    "for n in row_counts:\n",
    "    recent = X.index[-n:]\n",
    "    model, score = fit_model(t.loc[recent], X.loc[recent, :], y.loc[recent], distance=12)\n",
    "    scores.append(score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(100.0*np.array(row_counts)/X.shape[0], scores, lw=2)\n",
    "plt.axhline(max(scores), linestyle='--', color='gray')\n",
    "plt.xlabel('% recent rows')\n",
    "plt.ylabel('Test Score')\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(t, y, '-', lw=2)\n",
    "plt.axvline(t.iloc[-np.argmax(row_counts)], linestyle='--', color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = range(0, 36)\n",
    "scores = []\n",
    "\n",
    "for i in distances:\n",
    "    model, score = fit_model(t, X, y, distance=i)\n",
    "    scores.append(score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(distances, scores, lw=2)\n",
    "plt.xlabel('Forecast Distance')\n",
    "plt.ylabel('Test Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transform / Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv('data/air_passengers.csv', parse_dates=['date'])\n",
    "t = data['date']\n",
    "y = data['y']\n",
    "\n",
    "# normal\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(t, y)\n",
    "plt.ylabel('Normal')\n",
    "\n",
    "# differencing\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(t, y - y.shift(12), 'r')\n",
    "plt.ylabel('12 Month Differenced')\n",
    "\n",
    "# log transform\n",
    "log_y = y.apply(np.log)\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(t, log_y, 'g');\n",
    "plt.ylabel('Log Transformed')\n",
    "\n",
    "# both\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(t, log_y - log_y.shift(12), 'm')\n",
    "plt.ylabel('Differenced and Log Transformed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
