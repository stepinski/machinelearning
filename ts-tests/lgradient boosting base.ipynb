{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"Based on kernel - see it : https://www.kaggle.com/caesarlupum/ashrae-ligthgbm-simple-fe","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\n\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.patches as patches\nfrom scipy import stats\nfrom scipy.stats import skew\n\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\npd.set_option('max_columns', 100)\n\npy.init_notebook_mode(connected=True)\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nimport os,random, math, psutil, pickle\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#root = '../../../data/ashrae-energy-prediction/'\nroot = '../input/ashrae-energy-prediction/'\ndf_train_dtypes = {'building_id': np.uint16, 'meter': np.uint8, 'meter_reading': np.float32}\ndf_test_dtypes = {'building_id': np.uint16, 'meter': np.uint8}\ndf_building_metadata_dtypes = {'site_id': np.uint8, 'building_id': np.uint16, 'square_feet': np.int32, 'year_built': np.float32, 'floor_count': np.float32}\ndf_weather_dtypes = {'site_id': np.uint8, 'air_temperature': np.float32, 'cloud_coverage': np.float32, 'dew_temperature': np.float32,\n                     'precip_depth_1_hr': np.float32, 'sea_level_pressure': np.float32, 'wind_direction': np.float32, 'wind_speed': np.float32}\n\ndf_train = pd.read_csv(root+'train.csv', dtype=df_train_dtypes)\ndf_test = pd.read_csv(root+'test.csv', dtype=df_train_dtypes)\ndf_building_metadata = pd.read_csv(root+'building_metadata.csv', dtype=df_building_metadata_dtypes)\ndf_weather_train = pd.read_csv(root+'weather_train.csv', dtype=df_weather_dtypes)\ndf_weather_test = pd.read_csv(root+'weather_test.csv', dtype=df_weather_dtypes)\n\ndf_test.drop(columns=['row_id'], inplace=True)\n\ndf_train = df_train.merge(df_building_metadata, on='building_id', how='left')\ndf_train = df_train.merge(df_weather_train, on=['site_id', 'timestamp'], how='left')\ndf_test = df_test.merge(df_building_metadata, on='building_id', how='left')\ndf_test = df_test.merge(df_weather_test, on=['site_id', 'timestamp'], how='left')\n\ndel df_building_metadata, df_weather_train, df_weather_test\ngc.collect()\n\nprint('Training Set Shape = {}'.format(df_train.shape))\nprint('Test Set Shape = {}'.format(df_test.shape))\nprint('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\nprint('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(root + 'sample_submission.csv')\ndf_train[\"timestamp\"] = pd.to_datetime(df_train[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## REducing memory\ndf_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['floor_count'] = df_train['floor_count'].fillna(-999).astype(np.int16)\ndf_test['floor_count'] = df_test['floor_count'].fillna(-999).astype(np.int16)\n\ndf_train['year_built'] = df_train['year_built'].fillna(-999).astype(np.int16)\ndf_test['year_built'] = df_test['year_built'].fillna(-999).astype(np.int16)\n\ndf_train['cloud_coverage'] = df_train['cloud_coverage'].fillna(-999).astype(np.int16)\ndf_test['cloud_coverage'] = df_test['cloud_coverage'].fillna(-999).astype(np.int16) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoricals = [\"site_id\", \"building_id\", \"primary_use\",  \"meter\",  \"wind_direction\"] #\"hour\", \"weekday\",\ndrop_cols = [\"sea_level_pressure\", \"wind_speed\"]\n\nnumericals = [\"square_feet\", \"year_built\", \"air_temperature\", \"cloud_coverage\",\n              \"dew_temperature\", 'precip_depth_1_hr', 'floor_count']\n\nfeat_cols = categoricals + numericals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = np.log1p(df_train[\"meter_reading\"])\n\ndel df_train[\"meter_reading\"] \n\ndf_train = df_train.drop(drop_cols, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ndf_train['primary_use'] = le.fit_transform(df_train['primary_use']).astype(np.int8)\ndf_test['primary_use'] = le.fit_transform(df_test['primary_use']).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n            'boosting_type': 'gbdt',\n            'objective': 'regression',\n            'metric': {'rmse'},\n            'subsample_freq': 1,\n            'learning_rate': 0.3,\n            'bagging_freq': 5,\n            'num_leaves': 330,\n            'feature_fraction': 0.9,\n            'lambda_l1': 1,  \n            'lambda_l2': 1\n            }\n\nfolds = 5\nseed = 666\nshuffle = False\nkf = KFold(n_splits=folds, shuffle=shuffle, random_state=seed)\n\nmodels = []\nfor train_index, val_index in kf.split(df_train[feat_cols], df_train['building_id']):\n    train_X = df_train[feat_cols].iloc[train_index]\n    val_X = df_train[feat_cols].iloc[val_index]\n    train_y = target.iloc[train_index]\n    val_y = target.iloc[val_index]\n    lgb_train = lgb.Dataset(train_X, train_y, categorical_feature=categoricals)\n    lgb_eval = lgb.Dataset(val_X, val_y, categorical_feature=categoricals)\n    gbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=500,\n                valid_sets=(lgb_train, lgb_eval),\n                early_stopping_rounds=50,\n                verbose_eval = 50)\n    print(train_index)\n    models.append(gbm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel df_train #, train_X, val_X, lgb_train, lgb_eval, train_y, val_y, target\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df_test[feat_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nres=[]\nstep_size = 50000\nfor j in tqdm(range(int(np.ceil(df_test.shape[0]/50000)))):\n    res.append(np.expm1(sum([model.predict(df_test.iloc[i:i+step_size]) for model in models])/folds))\n    i+=step_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = np.concatenate(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['meter_reading'] = res\nsample_submission.loc[sample_submission['meter_reading']<0, 'meter_reading'] = 0\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}